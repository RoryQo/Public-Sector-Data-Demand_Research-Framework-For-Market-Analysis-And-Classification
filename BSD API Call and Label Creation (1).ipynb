{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc1bb86",
   "metadata": {},
   "source": [
    "### USAJOBS API Script\n",
    "\n",
    "This script contains the full API call to **USAJOBS** and the logic for generating labeled data used by the NLP classification model.\n",
    "\n",
    "#### ⚠️ Setup Instructions Before Running\n",
    "\n",
    "- **Update file paths**:  \n",
    "  Use `Ctrl + F` to find and replace all instances of  \n",
    "  `C://Users//...//` with your local directory path.\n",
    "\n",
    "- **Insert your API credentials**:  \n",
    "  Replace the placeholder `Authorization-Key` with your own key from [developer.usajobs.gov](https://developer.usajobs.gov).  \n",
    "  Ensure the **email address** used in the API header matches the one registered with your key.\n",
    "\n",
    "This script prepares raw job data and labeled examples for training the data buyer classification model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09883502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# API setup\n",
    "url = 'https://data.usajobs.gov/api/search'\n",
    "headers = {\n",
    "    'Host': 'data.usajobs.gov',\n",
    "    'User-Agent': 'email@email.com',\n",
    "    'Authorization-Key': 'authorization key'\n",
    "}\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = ['data', 'contract', 'analyst', 'machine learning', 'marketing', 'aquisition', 'finance', 'security','tech', 'purchasing', 'statistics', 'math', 'data scientist', 'research', 'economist']\n",
    "\n",
    "# Dictionary to collect all unique jobs\n",
    "all_jobs = {}\n",
    "\n",
    "for keyword in keywords:\n",
    "    print(f\"\\nSearching for keyword: {keyword}\")\n",
    "    params = {\n",
    "        'Keyword': keyword,\n",
    "        'ResultsPerPage': 500,\n",
    "        'Page': 1\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        jobs = data.get('SearchResult', {}).get('SearchResultItems', [])\n",
    "        if not jobs:\n",
    "            break\n",
    "\n",
    "        for job in jobs:\n",
    "            job_id = job.get('MatchedObjectId')\n",
    "            descriptor = job.get('MatchedObjectDescriptor', {})\n",
    "            details = descriptor.get('UserArea', {}).get('Details', {})\n",
    "\n",
    "            if job_id not in all_jobs:\n",
    "                all_jobs[job_id] = {\n",
    "                    'JobID': job_id,\n",
    "                    'JobTitle': descriptor.get('PositionTitle'),\n",
    "                    'JobDescription': details.get('JobSummary'),\n",
    "                    'KeyDuties': details.get('MajorDuties', 'N/A'),\n",
    "                    'Department': descriptor.get('OrganizationName'),\n",
    "                    'Agency': descriptor.get('DepartmentName'),\n",
    "                    'SearchKeywords': [keyword]  # First time seeing this job\n",
    "                }\n",
    "            else:\n",
    "                if keyword not in all_jobs[job_id]['SearchKeywords']:\n",
    "                    all_jobs[job_id]['SearchKeywords'].append(keyword)\n",
    "\n",
    "        print(f\"Retrieved page {params['Page']} with {len(jobs)} jobs\")\n",
    "        params['Page'] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "jobs_df = pd.DataFrame(list(all_jobs.values()))\n",
    "\n",
    "# Convert list of keywords to comma-separated string\n",
    "jobs_df['SearchKeywords'] = jobs_df['SearchKeywords'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Save to CSV\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_file_path = f'C://Users//...//all_keyword_job_listings.csv'\n",
    "jobs_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved {len(jobs_df)} unique job listings to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f920c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = 'C://Users//...//all_keyword_job_listings.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f155b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Combine JobDescription and KeyDuties into one text field for analysis\n",
    "df['CombinedText'] = (df['JobDescription'].fillna('') + ' ' + df['KeyDuties'].fillna('')).str.lower()\n",
    "\n",
    "# Define phrases related to data purchasing/acquisition\n",
    "related_phrases = [\n",
    "    \"data acquisition\", \"data procurement\", \"procure data\", \"purchase data\",\n",
    "    \"buy data\", \"acquiring data\", \"data sourcing\", \"data licensing\", \n",
    "    \"external data acquisition\", \"third-party data\", \"data vendor\", \n",
    "    \"data provider\", \"data contracts\", \"contracting data\", \"data subscriptions\",\n",
    "    \"vendor management\", \"external data\", \"commercial data\"\n",
    "]\n",
    "\n",
    "# Build regex pattern\n",
    "pattern = '|'.join([re.escape(phrase) for phrase in related_phrases])\n",
    "\n",
    "# Create binary column: 1 if any phrase found, 0 otherwise\n",
    "df['IsDataBuyer'] = df['CombinedText'].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "# Show label distribution\n",
    "print(\"Label distribution (IsDataBuyer):\")\n",
    "print(df['IsDataBuyer'].value_counts())\n",
    "\n",
    "# Display jobs that mention relevant phrases\n",
    "matches = df[df['IsDataBuyer'] == 1]\n",
    "print(f\"\\nFound {len(matches)} job(s) mentioning data acquisition or purchasing concepts.\\n\")\n",
    "\n",
    "# Display only selected columns (check for existence)\n",
    "columns_to_show = ['JobID', 'JobTitle', 'Department', 'Agency', 'SearchKeywords']\n",
    "display(matches[[col for col in columns_to_show if col in matches.columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17162502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsDataBuyer'] = df['CombinedText'].str.contains(pattern, case=False, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Define your list of signal phrases again\n",
    "signal_phrases = [\n",
    "    # Existing\n",
    "    \"data acquisition\", \"data procurement\", \"procure data\", \"purchase data\",\n",
    "    \"buy data\", \"acquiring data\", \"data sourcing\", \"data licensing\", \n",
    "    \"external data\", \"third-party data\", \"data vendor\", \n",
    "    \"data provider\", \"data contracts\", \"contracting data\", \"data subscriptions\",\n",
    "    \"vendor management\", \"commercial data\",\n",
    "\n",
    "    # New additions\n",
    "    \"data assets\", \"data commercialization\", \"procurement of data\", \"data\",\n",
    "    \"external data sources\", \"data aggregators\", \"data monetization\",\n",
    "    \"sourcing external data\", \"partner data\", \"data purchasing agreements\",\n",
    "    \"data ingestion\", \"subscription data\", \"data acquisition strategy\",\n",
    "    \"data buying\", \"external datasets\", \"external partnerships\", \"data sharing agreements\",\n",
    "    \"data acquisition channels\", \"third-party data sources\", \"sourcing data providers\",\n",
    "    \"managing data vendors\", \"data reseller\", \"external data vendors\", \"contracted data\"\n",
    "]\n",
    "\n",
    "\n",
    "# Function to check if any phrase matches fuzzily above a threshold\n",
    "def fuzzy_match_phrases(text, phrases, threshold=95):\n",
    "    for phrase in phrases:\n",
    "        score = fuzz.partial_ratio(phrase.lower(), text.lower())\n",
    "        if score >= threshold:\n",
    "            return phrase  # Return the matching phrase\n",
    "    return None\n",
    "\n",
    "# Apply fuzzy matching\n",
    "df['FuzzyMatchedPhrase'] = df['CombinedText'].apply(lambda x: fuzzy_match_phrases(x, signal_phrases, threshold=80))\n",
    "df['IsFuzzyMatch'] = df['FuzzyMatchedPhrase'].notnull().astype(int)\n",
    "\n",
    "# Filter and display fuzzy matches\n",
    "fuzzy_matches = df[df['IsFuzzyMatch'] == 1]\n",
    "display(fuzzy_matches[['JobID', 'JobTitle', 'FuzzyMatchedPhrase', 'Department', 'Agency']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8124284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both binary indicators into a single label\n",
    "df['IsLikelyDataBuyer'] = ((df['IsDataBuyer'] == 1) | (df['IsFuzzyMatch'] == 1)).astype(int)\n",
    "\n",
    "# View matching jobs\n",
    "combined_matches = df[df['IsLikelyDataBuyer'] == 1]\n",
    "display(combined_matches[['JobID', 'JobTitle', 'FuzzyMatchedPhrase', 'IsDataBuyer', 'IsFuzzyMatch', 'Department', 'Agency']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_agencies = [\n",
    "    \"Department of Defense\", \"Department of Veterans Affairs\", \"Department of the Treasury\",\n",
    "    \"Department of Homeland Security\", \"Department of Health and Human Services\",\n",
    "    \"Department of Justice\", \"Department of the Army\"\n",
    "]\n",
    "\n",
    "medium_agencies = [\n",
    "    \"Department of Transportation\", \"Department of Commerce\", \"Department of Agriculture\",\n",
    "    \"Department of Energy\", \"Department of the Interior\", \"National Aeronautics and Space Administration\"\n",
    "]\n",
    "\n",
    "# Any agency not listed above will be considered \"Small\"\n",
    "def classify_agency_size(agency):\n",
    "    if agency in large_agencies:\n",
    "        return 'Large'\n",
    "    elif agency in medium_agencies:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Small'\n",
    "\n",
    "# Apply classification\n",
    "df['AgencySize'] = df['Agency'].apply(classify_agency_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5542c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to classify each job\n",
    "def classify_industry(row):\n",
    "    text = f\"{row['JobTitle']} {row['Department']} {row['SearchKeywords']}\".lower()\n",
    "    \n",
    "    if any(x in text for x in ['finance', 'financial', 'account', 'budget']):\n",
    "        return 'Finance'\n",
    "    elif any(x in text for x in ['marketing', 'communications', 'advertising']):\n",
    "        return 'Marketing'\n",
    "    elif any(x in text for x in ['medical', 'pharmacy', 'nurse', 'health', 'clinical']):\n",
    "        return 'Medical'\n",
    "    elif any(x in text for x in ['cyber', 'security', 'information technology', 'it', 'data scientist', 'software', 'tech']):\n",
    "        return 'Security/Tech'\n",
    "    elif any(x in text for x in ['policy', 'regulation', 'legislative', 'analyst', 'compliance']):\n",
    "        return 'Policy'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply classification\n",
    "df['Industry'] = df.apply(classify_industry, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a binary flag for senior roles\n",
    "senior_keywords = ['senior', 'lead', 'chief', 'principal', 'director', 'head']\n",
    "\n",
    "df['IsSeniorRole'] = df['JobTitle'].str.lower().str.contains('|'.join(senior_keywords), na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcce4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define what counts as a data-related job\n",
    "data_keywords = ['data', 'analyst', 'scientist', 'analytics', 'it', 'information', 'statistician', 'intelligence']\n",
    "\n",
    "# 2. Create flag for explicitly data-related job titles\n",
    "df['IsExplicitDataJob'] = df['JobTitle'].str.lower().str.contains('|'.join(data_keywords), na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define use case keywords\n",
    "use_case_keywords = {\n",
    "    'Fraud': ['fraud', 'eligibility', 'verification', 'audit', 'compliance'],\n",
    "    'Sentiment': ['sentiment', 'public opinion', 'media monitoring', 'engagement', 'communication'],\n",
    "    'PatientMatching': ['patient match', 'interoperability', 'record linkage', 'ehr', 'health record'],\n",
    "    'AdTargeting': ['audience segmentation', 'targeting', 'ad performance', 'campaign data']\n",
    "}\n",
    "\n",
    "# Step 2: Create use case flags\n",
    "for use_case, keywords in use_case_keywords.items():\n",
    "    pattern = '|'.join(keywords)\n",
    "    df[f'UseCase_{use_case}'] = df['CombinedText'].str.lower().str.contains(pattern, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd259a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing categories\n",
    "df['Industry'] = df['Industry'].fillna('Other')\n",
    "df['AgencySize'] = df['AgencySize'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your reference generalist titles\n",
    "generalist_titles = [\n",
    "    'Contract Specialist',\n",
    "    'Grants Officer',\n",
    "    'Grants Specialist',\n",
    "    'Budget Officer',\n",
    "    'Administrative Officer',\n",
    "    'Operations Coordinator',\n",
    "    'Program Coordinator',\n",
    "    'Project Coordinator',\n",
    "    'Procurement Specialist',\n",
    "    'Procurement Analyst',\n",
    "    'Communications Specialist',\n",
    "    'Public Affairs Officer',\n",
    "    'Public Information Officer',\n",
    "    'Community Outreach Coordinator',\n",
    "    'Health IT Coordinator',\n",
    "    'Program Specialist',\n",
    "    'Program Manager',\n",
    "    'Business Operations Specialist'\n",
    "]\n",
    "\n",
    "\n",
    "# Function to determine if a job title is a generalist (fuzzy matched)\n",
    "def is_generalist(title, threshold=65):\n",
    "    match, score, _ = process.extractOne(title, generalist_titles, scorer=fuzz.partial_ratio)\n",
    "    return score >= threshold\n",
    "\n",
    "# Apply the fuzzy matching to classify generalist roles\n",
    "df['IsGeneralistRole'] = df['JobTitle'].apply(lambda x: is_generalist(str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e768ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full annotated DataFrame to CSV (includes all jobs + labels)\n",
    "df.to_csv('C://Users//...//all_jobs_with_data_buyer_labels.csv', index=False)\n",
    "print(\"Saved full job listings with data buyer indicators to: all_jobs_with_data_buyer_labels.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
