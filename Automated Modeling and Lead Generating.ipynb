{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533f40c1",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "This notebook performs **end-to-end classification of potential public sector data buyers** using structured and unstructured features from federal job postings. Specifically, it:\n",
    "\n",
    "- Loads and prepares USAJobs data scraped via the automated acquisition script\n",
    "- Applies preprocessing pipelines for both text and structured variables\n",
    "- Predicts buyer likelihood using a trained logistic regression model\n",
    "- Outputs:\n",
    "  - `PredictedLabel`: Binary indicator (1 = likely data buyer)\n",
    "  - `DataBuyerScore`: Probability from the model\n",
    "- Exports a **ranked lead list** of high-priority job postings for potential outreach or analysis\n",
    "\n",
    "###  Setup Steps Before Running\n",
    "\n",
    "1. **Set File Paths**  \n",
    "   Replace all file paths in the notebook with your own local paths.  \n",
    "   Use `Ctrl + F` to search for and replace all instances of the default path (`C://Users/.../`) with your desired directory.\n",
    "\n",
    "2. **Data File Consistency**  \n",
    "   Ensure the input CSV file has the **same name and format** as the one created by the automated data acquisition script.  \n",
    "   If you used the USAJobs fetcher provided in this repository, no changes are needed.\n",
    "\n",
    "3. **Pipeline Files**  \n",
    "   The notebook depends on pretrained pipeline files (`.pkl` files for vectorizers, transformers, and the classifier), which are **included in this repository**.  \n",
    "   Be sure they are **downloaded and saved in the correct folder** as referenced in the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "Once the setup is complete, simply run the notebook to generate buyer predictions and export the final lead list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c771897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model and vectorizer from the same folder as the notebook\n",
    "model = joblib.load('nlp_model.joblib')\n",
    "vectorizer = joblib.load('vectorizer.joblib')\n",
    "pipeline = joblib.load('nlp_pipeline_with_smote.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b55002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your new dataset of job descriptions (CSV example)\n",
    "# Replace with your actual file path and dataset of jobs\n",
    "df_new_jobs = pd.read_csv('C://Users//...//all_keyword_job_listings.csv')  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c15c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the same columns used during training: CombinedText, AgencySize, Industry, IsSeniorRole\n",
    "X_new = df_new_jobs[['CombinedText', 'AgencySize', 'Industry', 'IsSeniorRole']]\n",
    "\n",
    "# Transform the new data using the preprocessor part of the pipeline\n",
    "X_new_transformed = pipeline.named_steps['preprocessor'].transform(X_new)\n",
    "\n",
    "# Make predictions using the trained classifier\n",
    "predictions = pipeline.named_steps['classifier'].predict(X_new_transformed)\n",
    "\n",
    "# Add predictions to the new dataframe (0 or 1, where 1 is a data buyer)\n",
    "df_new_jobs['predicted_label'] = predictions\n",
    "\n",
    "# Filter data-buying leads (predicted_label == 1)\n",
    "data_buying_jobs = df_new_jobs[df_new_jobs['predicted_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45025016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-buying leads have been saved to 'predicted_data_buying_leads.csv'\n"
     ]
    }
   ],
   "source": [
    "# Optionally, save the predicted data-buying leads to a CSV file\n",
    "data_buying_jobs.to_csv('C://Users//...//predicted_data_buying_leads.csv', index=False)\n",
    "\n",
    "print(\"Data-buying leads have been saved to 'predicted_data_buying_leads.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
